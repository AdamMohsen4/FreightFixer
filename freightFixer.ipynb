{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMG+Qxddqukrbz9EV6Tx1A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamMohsen4/FreightFixer/blob/main/freightFixer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "f9dnPKCqLsPb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "import torch\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "\n",
        "if filename.endswith('.csv'):\n",
        "    df = pd.read_csv(filename)\n",
        "    print(\"Loaded CSV file successfully!\")\n",
        "\n",
        "elif filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
        "    df = pd.read_excel(filename)\n",
        "    print(\"Loaded Excel file successfully!\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file type. Please upload a CSV or Excel file.\")\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "iArqr86BOKDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "137953ea-3a63-4fc7-c61a-3ab05fe60546"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc1485da-9773-4263-85ba-b2444511834a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bc1485da-9773-4263-85ba-b2444511834a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving synthetic_shipment_data.csv to synthetic_shipment_data (5).csv\n",
            "Loaded CSV file successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           clean_name         clean_company             clean_street  \\\n",
              "0  Elisa Ruotsalainen             Saari Oyj   Orisaarenbulevardi 189   \n",
              "1         Juha Ojanen  Laitinen Kivinen Oyj    Agricolanbulevardi 45   \n",
              "2      Aino Penttinen  Eskelinen Perälä Oyj            Nikonkuja 109   \n",
              "3     Antero Nieminen   Lampinen Turunen Oy  Ahvenkoskenbulevardi 41   \n",
              "4    Susanna Koskinen  Pöllänen Räsänen Oyj      Maanmittarintie 125   \n",
              "\n",
              "   clean_postal_code clean_city        noisy_name  noisy_company  \\\n",
              "0               4300    Tuusula               NaN         4300.0   \n",
              "1              80100    Joensuu       Juha Ojanen        80100.0   \n",
              "2              15110      Lahti   Aino Peenttinen        15110.0   \n",
              "3              20100      Turku   Antero Nieminen        20100.0   \n",
              "4              80100    Joensuu  Susanna KosinenX        80100.0   \n",
              "\n",
              "              noisy_street  noisy_postal_code noisy_city  \n",
              "0  Oirsaarenybulevardi 189             1300.0    Tuuslua  \n",
              "1    Agricolanbuleavrdi 45                NaN    Joensuu  \n",
              "2             Nikonkua 109                NaN      alhti  \n",
              "3  Ahvnekoskenbulevardi 41            20100.0      Tukru  \n",
              "4      Maanmittarintie 125            80140.0    joensuu  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d6430b4-550c-4134-9f32-0bf4c9cc5542\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_name</th>\n",
              "      <th>clean_company</th>\n",
              "      <th>clean_street</th>\n",
              "      <th>clean_postal_code</th>\n",
              "      <th>clean_city</th>\n",
              "      <th>noisy_name</th>\n",
              "      <th>noisy_company</th>\n",
              "      <th>noisy_street</th>\n",
              "      <th>noisy_postal_code</th>\n",
              "      <th>noisy_city</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elisa Ruotsalainen</td>\n",
              "      <td>Saari Oyj</td>\n",
              "      <td>Orisaarenbulevardi 189</td>\n",
              "      <td>4300</td>\n",
              "      <td>Tuusula</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4300.0</td>\n",
              "      <td>Oirsaarenybulevardi 189</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>Tuuslua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Juha Ojanen</td>\n",
              "      <td>Laitinen Kivinen Oyj</td>\n",
              "      <td>Agricolanbulevardi 45</td>\n",
              "      <td>80100</td>\n",
              "      <td>Joensuu</td>\n",
              "      <td>Juha Ojanen</td>\n",
              "      <td>80100.0</td>\n",
              "      <td>Agricolanbuleavrdi 45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joensuu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aino Penttinen</td>\n",
              "      <td>Eskelinen Perälä Oyj</td>\n",
              "      <td>Nikonkuja 109</td>\n",
              "      <td>15110</td>\n",
              "      <td>Lahti</td>\n",
              "      <td>Aino Peenttinen</td>\n",
              "      <td>15110.0</td>\n",
              "      <td>Nikonkua 109</td>\n",
              "      <td>NaN</td>\n",
              "      <td>alhti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Antero Nieminen</td>\n",
              "      <td>Lampinen Turunen Oy</td>\n",
              "      <td>Ahvenkoskenbulevardi 41</td>\n",
              "      <td>20100</td>\n",
              "      <td>Turku</td>\n",
              "      <td>Antero Nieminen</td>\n",
              "      <td>20100.0</td>\n",
              "      <td>Ahvnekoskenbulevardi 41</td>\n",
              "      <td>20100.0</td>\n",
              "      <td>Tukru</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Susanna Koskinen</td>\n",
              "      <td>Pöllänen Räsänen Oyj</td>\n",
              "      <td>Maanmittarintie 125</td>\n",
              "      <td>80100</td>\n",
              "      <td>Joensuu</td>\n",
              "      <td>Susanna KosinenX</td>\n",
              "      <td>80100.0</td>\n",
              "      <td>Maanmittarintie 125</td>\n",
              "      <td>80140.0</td>\n",
              "      <td>joensuu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d6430b4-550c-4134-9f32-0bf4c9cc5542')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d6430b4-550c-4134-9f32-0bf4c9cc5542 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d6430b4-550c-4134-9f32-0bf4c9cc5542');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6df25cd7-7872-4cce-bb0e-2daff094876d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6df25cd7-7872-4cce-bb0e-2daff094876d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6df25cd7-7872-4cce-bb0e-2daff094876d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"clean_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4851,\n        \"samples\": [\n          \"Kari K\\u00e4rki\",\n          \"Samu Mikkola\",\n          \"Niilo Ojala\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3762,\n        \"samples\": [\n          \"Saarela Tmi\",\n          \"Kulmala Hakala Ky\",\n          \"M\\u00e4ntyl\\u00e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_street\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4939,\n        \"samples\": [\n          \"Winqvistinkuja 36\",\n          \"Py\\u00f6r\\u00f6kiventie 56\",\n          \"Cygnaeuksenkatu 154\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_postal_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32033,\n        \"min\": 100,\n        \"max\": 90100,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          100,\n          80100,\n          1600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_city\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Helsinki\",\n          \"Joensuu\",\n          \"Vantaa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noisy_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4266,\n        \"samples\": [\n          \"Raili Andersson\",\n          \"Ritva KoQanen\",\n          \"Maria Laine-Salonen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noisy_company\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32077.760302912582,\n        \"min\": 0.0,\n        \"max\": 99100.0,\n        \"num_unique_values\": 376,\n        \"samples\": [\n          90103.0,\n          5410.0,\n          20120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noisy_street\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4512,\n        \"samples\": [\n          \"Jyv\\u00e4pklu 84\",\n          \"Haapakuja1 02\",\n          \"Fallpakaknuja 87\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noisy_postal_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32376.732169445604,\n        \"min\": 0.0,\n        \"max\": 99100.0,\n        \"num_unique_values\": 395,\n        \"samples\": [\n          3100.0,\n          33700.0,\n          80150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noisy_city\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 325,\n        \"samples\": [\n          \"V\\u00e4rd\\u00f6\",\n          \"oJensuu\",\n          \"Oulainen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and filter data (just city for now)\n",
        "df = df[['noisy_city', 'clean_city']]\n",
        "# df = df.dropna()\n",
        "df = df.astype(str)\n",
        "\n",
        "# Buid character vocabulary\n",
        "all_text = ''.join(df['noisy_city']) + '' .join(df['clean_city'])\n",
        "chars = sorted(set(all_text))\n",
        "char2idx = {c: i+1 for i, c in enumerate(chars)}\n",
        "idx2char = {i+1: c for i, c in enumerate(chars)}\n",
        "vocab_size = len(char2idx) + 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xpAozZZEOq1E"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Convert a string into a list of integers using the character-to-index mapping.\n",
        "    The string is converted to lowercase (optional) for consistency.\n",
        "    If the resulting list is shorter than max_len, pad it with 0s (the padding token).\n"
      ],
      "metadata": {
        "id": "5evIQ4uBDanv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to indexed sequences\n",
        "\n",
        "def encode(text, char2idx, max_len):\n",
        "  encoded = [char2idx.get(c,0) for c in text.lower()]\n",
        "  return encoded + [0]*(max_len - len(encoded))\n",
        "\n",
        "max_input_len = df['noisy_city'].str.len().max()\n",
        "max_target_len = df['clean_city'].str.len().max()\n",
        "\n",
        "inputs = [encode(x, char2idx, max_input_len) for x in df['noisy_city']]\n",
        "targets = [encode(x, char2idx, max_target_len) for x in df['clean_city']]"
      ],
      "metadata": {
        "id": "RmJ5hutYs2rq"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom PyTorch Dataset class.\n",
        "    It provides easy access to each input-target pair and converts the lists into tensors.\n"
      ],
      "metadata": {
        "id": "Aaki8i_QDZvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CorrectionDataset(Dataset):\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = torch.tensor(inputs, dtype = torch.long)\n",
        "    self.targets = torch.tensor(targets, dtype = torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]\n",
        "\n",
        "dataset = CorrectionDataset(inputs, targets)\n",
        "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)\n"
      ],
      "metadata": {
        "id": "rRCyBKtdxHqp"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Encoder reads the input sequence and encodes it into a context vector.\n",
        "    It uses an Embedding layer to convert indices to vector representations,\n",
        "    followed by an LSTM layer to process the sequence.\n"
      ],
      "metadata": {
        "id": "vDWXcVppDUnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__ (self, vocab_size, embed_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    _, (hidden, cell) = self.lstm(embedded)\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "zuU0Ogy4-Yvc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Decoder generates the output sequence based on the encoded context from the Encoder.\n",
        "    It also uses an Embedding layer for input tokens, an LSTM to process the sequence,\n",
        "    and a Fully Connected layer to predict the next token.\n",
        "    \n"
      ],
      "metadata": {
        "id": "vb5L1sqp0N9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c8uEChoT0P9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "      super().__init__()\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
        "      self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
        "      self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "      embedded = self.embedding(x)\n",
        "      output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "      prediction = self.fc(output)\n",
        "      return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "n3ItWZqEpPTl"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Seq2Seq model integrates both the Encoder and Decoder.\n",
        "    It loops over each time step to generate the output sequence.\n",
        "    Teacher forcing is optionally used during training.\n"
      ],
      "metadata": {
        "id": "q0a0SW1O3bDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target=None, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1] if target is not None else max_target_len  # Use max_target_len when target is None\n",
        "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "        # Start with <SOS> token (if you have one, otherwise use a suitable start token)\n",
        "        decoder_input = torch.tensor([char2idx.get(\"<SOS>\", 0)] * batch_size, dtype=torch.long, device=device)\n",
        "\n",
        "        for t in range(target_len):\n",
        "            decoder_input = decoder_input.unsqueeze(1)  # Reshape for LSTM input\n",
        "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
        "            outputs[:, t, :] = output.squeeze(1)\n",
        "\n",
        "            # Teacher forcing\n",
        "            if target is not None and random.random() < teacher_forcing_ratio:\n",
        "                decoder_input = target[:, t]  # Use ground truth\n",
        "            else:\n",
        "                decoder_input = torch.argmax(output, dim=2).squeeze(1)  # Use model prediction\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "ef0CT9fs3Whm"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize model and set up training"
      ],
      "metadata": {
        "id": "RhZNN1SF6FqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "\n",
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim)\n",
        "decoder = Decoder(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for input_batch, target_batch in dataloader:\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Get model predictions for the current batch using teacher forcing\n",
        "        output = model(input_batch, target_batch)\n",
        "\n",
        "        loss = criterion(output.view(-1, vocab_size), target_batch.view(-1))\n",
        "        loss.backward()  # Compute gradients via backpropagation\n",
        "        optimizer.step()  # Update model weights using the optimizer\n",
        "        total_loss += loss.item()  # Add the batch loss to the epoch loss\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)  # Average loss for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ1mzhT76FD0",
        "outputId": "206dba1d-1878-4f7e-8112-24554ec2c71e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Average Loss: 1.1757\n",
            "Epoch 2/100, Average Loss: 0.1082\n",
            "Epoch 3/100, Average Loss: 0.0735\n",
            "Epoch 4/100, Average Loss: 0.0751\n",
            "Epoch 5/100, Average Loss: 0.0550\n",
            "Epoch 6/100, Average Loss: 0.0592\n",
            "Epoch 7/100, Average Loss: 0.0573\n",
            "Epoch 8/100, Average Loss: 0.0565\n",
            "Epoch 9/100, Average Loss: 0.0519\n",
            "Epoch 10/100, Average Loss: 0.0461\n",
            "Epoch 11/100, Average Loss: 0.0576\n",
            "Epoch 12/100, Average Loss: 0.0549\n",
            "Epoch 13/100, Average Loss: 0.0424\n",
            "Epoch 14/100, Average Loss: 0.0453\n",
            "Epoch 15/100, Average Loss: 0.0431\n",
            "Epoch 16/100, Average Loss: 0.0425\n",
            "Epoch 17/100, Average Loss: 0.0468\n",
            "Epoch 18/100, Average Loss: 0.0422\n",
            "Epoch 19/100, Average Loss: 0.0371\n",
            "Epoch 20/100, Average Loss: 0.0372\n",
            "Epoch 21/100, Average Loss: 0.0388\n",
            "Epoch 22/100, Average Loss: 0.0379\n",
            "Epoch 23/100, Average Loss: 0.0340\n",
            "Epoch 24/100, Average Loss: 0.0399\n",
            "Epoch 25/100, Average Loss: 0.0385\n",
            "Epoch 26/100, Average Loss: 0.0329\n",
            "Epoch 27/100, Average Loss: 0.0298\n",
            "Epoch 28/100, Average Loss: 0.0270\n",
            "Epoch 29/100, Average Loss: 0.0267\n",
            "Epoch 30/100, Average Loss: 0.0284\n",
            "Epoch 31/100, Average Loss: 0.0274\n",
            "Epoch 32/100, Average Loss: 0.0273\n",
            "Epoch 33/100, Average Loss: 0.0254\n",
            "Epoch 34/100, Average Loss: 0.0311\n",
            "Epoch 35/100, Average Loss: 0.0257\n",
            "Epoch 36/100, Average Loss: 0.0255\n",
            "Epoch 37/100, Average Loss: 0.0274\n",
            "Epoch 38/100, Average Loss: 0.0297\n",
            "Epoch 39/100, Average Loss: 0.0254\n",
            "Epoch 40/100, Average Loss: 0.0268\n",
            "Epoch 41/100, Average Loss: 0.0253\n",
            "Epoch 42/100, Average Loss: 0.0244\n",
            "Epoch 43/100, Average Loss: 0.0279\n",
            "Epoch 44/100, Average Loss: 0.0249\n",
            "Epoch 45/100, Average Loss: 0.0255\n",
            "Epoch 46/100, Average Loss: 0.0260\n",
            "Epoch 47/100, Average Loss: 0.0251\n",
            "Epoch 48/100, Average Loss: 0.0203\n",
            "Epoch 49/100, Average Loss: 0.0262\n",
            "Epoch 50/100, Average Loss: 0.0265\n",
            "Epoch 51/100, Average Loss: 0.0213\n",
            "Epoch 52/100, Average Loss: 0.0245\n",
            "Epoch 53/100, Average Loss: 0.0229\n",
            "Epoch 54/100, Average Loss: 0.0236\n",
            "Epoch 55/100, Average Loss: 0.0222\n",
            "Epoch 56/100, Average Loss: 0.0258\n",
            "Epoch 57/100, Average Loss: 0.0243\n",
            "Epoch 58/100, Average Loss: 0.0240\n",
            "Epoch 59/100, Average Loss: 0.0240\n",
            "Epoch 60/100, Average Loss: 0.0240\n",
            "Epoch 61/100, Average Loss: 0.0302\n",
            "Epoch 62/100, Average Loss: 0.0257\n",
            "Epoch 63/100, Average Loss: 0.0295\n",
            "Epoch 64/100, Average Loss: 0.0233\n",
            "Epoch 65/100, Average Loss: 0.0194\n",
            "Epoch 66/100, Average Loss: 0.0228\n",
            "Epoch 67/100, Average Loss: 0.0227\n",
            "Epoch 68/100, Average Loss: 0.0260\n",
            "Epoch 69/100, Average Loss: 0.0208\n",
            "Epoch 70/100, Average Loss: 0.0203\n",
            "Epoch 71/100, Average Loss: 0.0229\n",
            "Epoch 72/100, Average Loss: 0.0229\n",
            "Epoch 73/100, Average Loss: 0.0275\n",
            "Epoch 74/100, Average Loss: 0.0302\n",
            "Epoch 75/100, Average Loss: 0.0242\n",
            "Epoch 76/100, Average Loss: 0.0219\n",
            "Epoch 77/100, Average Loss: 0.0224\n",
            "Epoch 78/100, Average Loss: 0.0270\n",
            "Epoch 79/100, Average Loss: 0.0229\n",
            "Epoch 80/100, Average Loss: 0.0246\n",
            "Epoch 81/100, Average Loss: 0.0177\n",
            "Epoch 82/100, Average Loss: 0.0185\n",
            "Epoch 83/100, Average Loss: 0.0221\n",
            "Epoch 84/100, Average Loss: 0.0225\n",
            "Epoch 85/100, Average Loss: 0.0202\n",
            "Epoch 86/100, Average Loss: 0.0244\n",
            "Epoch 87/100, Average Loss: 0.0210\n",
            "Epoch 88/100, Average Loss: 0.0232\n",
            "Epoch 89/100, Average Loss: 0.0229\n",
            "Epoch 90/100, Average Loss: 0.0211\n",
            "Epoch 91/100, Average Loss: 0.0241\n",
            "Epoch 92/100, Average Loss: 0.0216\n",
            "Epoch 93/100, Average Loss: 0.0192\n",
            "Epoch 94/100, Average Loss: 0.0204\n",
            "Epoch 95/100, Average Loss: 0.0188\n",
            "Epoch 96/100, Average Loss: 0.0254\n",
            "Epoch 97/100, Average Loss: 0.0227\n",
            "Epoch 98/100, Average Loss: 0.0217\n",
            "Epoch 99/100, Average Loss: 0.0277\n",
            "Epoch 100/100, Average Loss: 0.0241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bh3or5jJ8aMm"
      }
    }
  ]
}